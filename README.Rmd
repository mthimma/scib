---
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk
set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "80%",
  warning = FALSE,
  message = FALSE
)
```

# scib

<!-- badges: start -->
<!-- badges: end -->

The goal of scib (single-cell integration and benchmarking) is to provide a unified way to perform data integration and benchmarking when the ground truth is available.

TEST

# INSTALLATION

You can install the latest version scib like so:

```{r, eval=FALSE}
library(remotes)
install_github("mthimma/scib")
```

# LOAD DATA FOR DEMONSTRATION

We will load the `pbmc.demo` dataset that is used in the fundamental Seurat vignette. This is a Seurat object containing 2,700 peripheral blood mononuclear cells (PBMC) from 10X genomics. See `help(pbmc.demo)` for more details.

```{r}
library(tidyverse)
library(Seurat)
library(SeuratWrappers)
library(rliger)
library(scib)
data(pbmc.demo)
pbmc.demo
```


## Quality control

Like all single-cell dataset, we need to perform quality control to ensure high quality dataset. Here we conduct a lenient quality control.

```{r}
pbmc.demo$percent.mt <- PercentageFeatureSet(pbmc.demo, pattern = "^MT-|^Mt-")

VlnPlot(pbmc.demo, c("nCount_RNA", "nFeature_RNA", "percent.mt"))

pbmc.demo <- subset(pbmc.demo,
                      nFeature_RNA > 200 &
                      nFeature_RNA < 2500 &
                      percent.mt   < 5)
```

Aside: After quality control

```{r}
pbmc.demo

VlnPlot(pbmc.demo, c("nCount_RNA", "nFeature_RNA", "percent.mt"))
```

## Ground truth

This dataset includes `seurat_annotations` provided by the Seurat co-authors. We also included a `batch` column which is artificially created for this package demonstration.

```{r}
pbmc.demo@meta.data %>%
  glimpse()
```

```{r}
pbmc.demo@meta.data %>% 
  janitor::tabyl(seurat_annotations, batch)
```

# DATA INTEGRATION

Aside: Seurat v5 stores information in the following layers

* `counts` layer: raw un-normalized counts
* `data` layer: normalized data, which is set correctly after `NormalizeData()`
* `scale.data` layer: z-scored/variance-stabilized data, which is set after `ScaleData()`

Here are the layers before the split

```{r}
Layers(pbmc.demo)
```


## Step 1: Split the Seurat object

We will split the RNA assay by the grouping factor that defines the batch effect. In reality, batch effects may arise from differences between donors, single-cell technology, sequencing platforms, timing, reagents, or experimental conditions across laboratories.

```{r}
pbmc.demo[["RNA"]] <- split(pbmc.demo[["RNA"]], f = pbmc.demo$batch)
```

Aside: We now can see that the counts and data layer has been split into three layers each.

```{r}
Layers(pbmc.demo)
```

## Step 2: Preprocess each split

Next we need to run the standard preprocessing steps for each split. This can be done via:

```{r}
pbmc.demo <- pbmc.demo %>%
  NormalizeData(verbose = FALSE) %>%
  FindVariableFeatures(verbose = FALSE) %>%
  ScaleData(verbose = FALSE) %>%
  RunPCA(verbose = FALSE)
```

We can see this has created the `pca` reduction based on the unintegrated data. We can determine the dimensional of this dataset from the Elbow plot to be approximately 10.

```{r}
Reductions(pbmc.demo)

ElbowPlot(pbmc.demo, ndims = 50, reduction = "pca")

ndims <- 10
```


## Step 3: Data integration step

This is the workhorse of the data integration process. Here is an example on how to execute this with Conos. The integrated embedding is stored in the `integrated.conos` reduction.

```{r, echo=FALSE}
set.seed(123)  # to fix the random seed for consistency in the .md output
```

```{r}
pbmc.demo <- IntegrateLayers2(pbmc.demo,
                             method         = "CONOSIntegration",
                             orig.reduction = "pca",
                             new.reduction  = "integrated.conos",
                             verbose        = FALSE,
                             resolution     = 0.80,
                             ndims          = ndims)

Reductions(pbmc.demo)
```

Other available methods that can be used with `IntegrateLayers()`:


| method             | package        | Publication                              | DOI                                          |
|---                 |---             |---                                       |---                                           |
| HarmonyIntegration | Seurat         | Korsunsky, I. et al. Nat Methods (2019). | https://doi.org/10.1038/s41592-019-0619-0    |
| CCAIntegration2    | Seurat$^*$     | Stuart T. et al. Cell. (2019).           | https:://doi.org/10.1016/j.cell.2019.05.031  |
| RPCAIntegration2   | Seurat$^*$     | Stuart T. et al. Cell. (2019).           | https:://doi.org/10.1016/j.cell.2019.05.031  |
| SCVI               | SeuratWrapper  | Lopez, R.et al. Nat Methods (2018)| https://doi.org/10.1038/s41592-018-0229-2  |        |
| FastMNN | SeuratWrapper       |  Haghverdi, L. et al. Nat. Biotechnol. (2018).         |DOI for FastMNN|
| LIGER   | scib (this package) |   Liu, J.et al. Nat Protocols (2020) | https://doi.org/10.1038/s41596-020-0391-8  |     |
| BBKNN   | scib (this package) |  Krzysztof PolaÅ„ski et al. Bioinformatics, 2020 | DOI for BBKNN|        |

$^*$ Minor modifications introduced in SCIB package.

## Step 4: Processing the integrated data

We can now run the non-linear dimension reduction on the integrated embedding and save it. Here the `ndims` is the dimensionality of the dataset that we determined earlier.

```{r, warning=FALSE}
pbmc.demo <- RunUMAP(pbmc.demo,
                     dims           = 1:ndims,
                     reduction      = "integrated.conos",
                     reduction.name = "umap.conos",
                     verbose        = FALSE
)
```

Next we cluster the cells at certain resolution based on the integrated embedding. We chose `res = 0.80` here but you should determine this for your own dataset.

```{r}
pbmc.demo <- FindNeighbors(pbmc.demo, reduction = "integrated.conos")

pbmc.demo <- FindClusters (pbmc.demo, res = 0.80, cluster.name = "conos.cluster")

DimPlot(pbmc.demo,
        reduction = "umap.conos",
        group.by  = "conos.cluster",
        label     = TRUE) +
  NoLegend()
```


## (optional) Step 5: Cleanup after data integration

The split layers counts and data can be joined after the data integration.


After the data integration, we no longer need the counts and data to be split by the batch variable. 
Similarly, we do not need the `scale.data` layer which being a non-sparse matrix takes a lot of space.

```{r}
Layers(pbmc.demo)

object.size(pbmc.demo) %>% format(units = "Mb")
```

Therefore we can join the layers and remove the `scale.data` to reduce object size.

```{r}
pbmc.demo <- JoinLayers(pbmc.demo)

pbmc.demo[["RNA"]]$scale.data  <- NULL
```

We can confirm this by checking the layers and observing the reduction in object size (from 100Mb to 60Mb).

```{r}
Layers(pbmc.demo)  

object.size(pbmc.demo) %>% format(units = "Mb")  
```


# EVALUATION

## Cross tabulation with the ground truth

We can compare the clusters based on the integrated embedding vs. the ground truth provided by the Seurat authors:

```{r, eval = FALSE}
tb <- table(pbmc.demo$seurat_annotations, pbmc.demo$conos.cluster)

print.table(tb, zero.print = ".")
#                0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16
# Naive CD4 T    .   . 161 158  23 139  24  21  45   .   1 124   .   1   .   .   .
# Memory CD4 T   .   .  23  18  24  34 133 128 111   .   .  12   .   .   .   .   .
# CD14+ Mono     .  43   .   .   .   .   .   .   . 146   .   . 119   .  97  75   .
# B            271   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  73
# CD8 T          1   .   .   5 127   .   7  10   .   . 114   1   .   6   .   .   .
# FCGR3A+ Mono   . 162   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .
# NK             .   .   .   .   .   .   .   .   .   .  33   .   . 122   .   .   .
# DC             3   .   .   .   .   .   .   .   .   .   .   .  10   .   8  11   .
```

There are several ways of estimating the performance of the data integration technique. Accuracy is one of the simpler method. 

1. Assign every cluster to one label using simple majority (e.g. 0 = B, 1 = FCGR3A+ Mono). 

2. Add up the numbers that correspond to this majority based assignment: 271 + 162 + 161 + 158 + 127 + 139 + 133 + 128 + 111 + 146 + 114 + 124 + 119 + 122 +  + 97 +  + 75 +  + 73. This totals to 2260.

3. Divide by the total number of cells. i.e. 2260 / 2638 which gives 85.7%.

However, there are more sophisticated metrics for evaluation which we cover next.


## Evaluate the data integration

```{r, eval = FALSE}
results <- run_eval_metrics(pbmc.demo, 
                            reduction      = "integrated.conos", 
                            groundtruth.cn = "seurat_annotations", 
                            predicted.cn   = "conos.cluster")

data.frame(results)
#                         results
# n_celltype           9.00000000
# ari_celltype         0.35552785
# nmi_celltype         0.52750372
# asw_celltype         0.30354695
# lisi_mean_celltype   0.14321150
# lisi_median_celltype 0.04628172
# n_batch              3.00000000
# ari_batch            0.11329078
# nmi_batch            0.20922764
# asw_batch            0.01923986
# lisi_mean_batch      0.22436669
# lisi_median_batch    0.02954152
# kbet_batch           0.12689394
```


# EVALUATING MULTIPLE METHODS

## Data preparation

Let us demonstrate how to run and evaluate mutiple data integration techniques. Let us reset the pbmc.demo data first.

```{r}
rm(pbmc.demo)
data(pbmc.demo, package = "scib")
```

Next we can run through Steps 1 - 2 to prepare the data again
```{r}
pbmc.demo[["RNA"]] <- split(pbmc.demo[["RNA"]], f = pbmc.demo$batch)

pbmc.demo <- pbmc.demo %>%
  NormalizeData(verbose = FALSE) %>%
  FindVariableFeatures(verbose = FALSE) %>%
  ScaleData(verbose = FALSE) %>%
  RunPCA(verbose = FALSE)

ndims <- 10  # determined from Elbowplot(pbmc.demo) earlier
```


## Multi method evaluation

Let's demonstrate Steps 3 - 4 with three methods.

```{r, warnings=FALSE, message=FALSE}
methods <- c(#harmony = "HarmonyIntegration",
             #conos   = "CONOSIntegration",
             #cca     = "CCAIntegration",
             #rpca    = "RPCAIntegration",
             scmc     = "SCMCIntegration"
             #liger     = "LIGERIntegration",
             #fastmnn   = "FastMNNIntegration",
             #bbknn   = "BBKNNIntegration",
             #scvi    = "scVIIntegration2"
             #scanorama = "SCANORAMAIntegration"
             
             )

big.res <- list()

for(i in 1:length(methods)){
  
  new.reduction.name <- names(methods)[i]
  new.cluster.name   <- paste0( names(methods)[i], ".cluster" )
  
  ## Step 3
  pbmc.demo <- IntegrateLayers2(pbmc.demo,
                               method         = methods[i],
                               orig.reduction = "pca",
                               new.reduction  = new.reduction.name,
                               verbose        = FALSE,
                               ndims          = ndims,
                               conda_env       = "/home/manjula/miniforge3/envs/sc" 
                               )
  
  ## Step 4
  pbmc.demo <- FindNeighbors(pbmc.demo, reduction = new.reduction.name)
  pbmc.demo <- FindClusters (pbmc.demo, res = 0.80, cluster.name = new.cluster.name)
  pbmc.demo$seurat_clusters <- NULL

  ## Evaluation step
  res <- run_eval_metrics(pbmc.demo, 
                          reduction      = new.reduction.name, 
                          groundtruth.cn = "seurat_annotations", 
                          predicted.cn   = new.cluster.name)
  
  res <- data.frame(res)
  colnames(res) <- new.reduction.name
  big.res[[i]]  <- res
  
  ## Cleanup
  rm(new.reduction.name, new.cluster.name, res)
  pbmc.demo@graphs$RNA_nn  <- NULL
  pbmc.demo@graphs$RNA_snn <- NULL
}

big.res <- do.call("cbind", big.res)
big.res
```

We can join the count and data layers and remove the `scale.data` layer as demonstrated in Step 5 if we have completed our testing.
